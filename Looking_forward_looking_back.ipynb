{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from os.path import splitext\n",
    "from os.path import basename\n",
    "import numpy as np\n",
    "import datetime\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = \"/path/to/indir/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to extract filename from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ext(filepath):\n",
    "    root, ext = splitext(filepath)\n",
    "    return root\n",
    "\n",
    "def get_filename(filepath):\n",
    "    return basename(remove_ext(filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe \n",
    "Df with the texts in \"text\" column and the file name (=date) in \"file_name\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = defaultdict(list)\n",
    "\n",
    "for root, dirs, files in os.walk(indir):\n",
    "    for filename in files:\n",
    "        filepath = root + os.sep + filename\n",
    "        if filename.startswith(\".\"):\n",
    "            continue\n",
    "        with open(filepath, 'r') as f:\n",
    "            text = f.read()\n",
    "            results[\"file_name\"].append(get_filename(remove_ext(filepath)))\n",
    "            results[\"text\"].append(text)\n",
    "\n",
    "corpus = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(corpus.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn \"file_name\" column into datetime and set as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[\"date\"] = pd.to_datetime(corpus[\"file_name\"], format =\"%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.set_index(\"date\")\n",
    "del corpus[\"file_name\"]\n",
    "corpus = corpus.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply preprocessing\n",
    "\n",
    "Lemmatization, stopwords, alphanumerical; store as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = [w for w in word_tokenize(text.lower()) if w.isalnum()]\n",
    "    text_str = ' '.join(text)\n",
    "    return text_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['clean_words'] = corpus['text'].apply(clean_text)\n",
    "print(corpus.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding and visualizing (ngram) strings in the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(string):\n",
    "    words = string.split()\n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['num_words'] = corpus['text'].apply(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_column(i):\n",
    "    i_df = i.replace(' ','_')\n",
    "    return i_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['one', 'two', 'ten']\n",
    "fig = plt.figure(figsize = (15,8))\n",
    "ax = plt.gca()\n",
    "\n",
    "for year in years:\n",
    "    if year == 'one':\n",
    "        years_ago = year + ' year ago'\n",
    "    else:\n",
    "        years_ago = year + ' years ago'\n",
    "    years_from_now1 = 'in ' + year + ' years'\n",
    "    years_from_now2 = year + ' from now'\n",
    "    corpus[query_column(years_ago)] = corpus.clean_words.str.count(years_ago) / corpus.num_words\n",
    "    corpus[query_column(years_from_now2)] = (corpus.clean_words.str.count(years_from_now1)+corpus.clean_words.str.count(years_from_now2)) / corpus.num_words\n",
    "    color = next(ax._get_lines.prop_cycler)['color']\n",
    "    plt.plot(corpus.index, corpus[query_column(years_ago)], color=color, marker='.', label=years_ago)\n",
    "    plt.plot(corpus.index, corpus[query_column(years_from_now2)], color=color, marker='.', linestyle='--', label=years_from_now2)\n",
    "    \n",
    "plt.ylabel('frequency')\n",
    "plt.xlabel('year')\n",
    "plt.title(\"Looking back and forward\")\n",
    "plt.legend()\n",
    "plt.minorticks_on()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_year = '1970'\n",
    "year_text = corpus.loc[get_year, 'clean_words']\n",
    "year_text_list = year_text.split()\n",
    "columns = ['first', 'second', 'third']\n",
    "ngrams_df = pd.DataFrame(ngrams(one_text_list, 3), columns = columns).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ngrams_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ngrams_df['trigrams'] = ngrams_df['first'].str.cat([ngrams_df['second'], ngrams_df['third']], sep=' ')\n",
    "ngrams_df.drop(['first', 'second', 'third'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make new dataframe of trigrams ending with specific words (here 'years ago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_ago_df = pd.DataFrame(ngrams_df['trigrams'][ngrams_df['trigrams'].str.endswith(\"years ago\")]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save sorted value counts of trigrams dataframe to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = '/path/to/outdir/years_ago_' + get_year + '.csv'\n",
    "years_ago_sorted = years_ago_df.value_counts()\n",
    "years_ago_sorted.to_csv(csv, sep='\\t', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
